{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee52763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3010 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Epoch 1/10\n",
      "301/301 [==============================] - 42s 135ms/step - loss: 0.4583 - accuracy: 0.9561 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 18s 61ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 19s 64ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "301/301 [==============================] - 19s 63ms/step - loss: 7.4701e-04 - accuracy: 1.0000 - val_loss: 9.8949e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "301/301 [==============================] - 19s 64ms/step - loss: 5.5483e-04 - accuracy: 1.0000 - val_loss: 7.6513e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "301/301 [==============================] - 19s 64ms/step - loss: 4.3838e-04 - accuracy: 1.0000 - val_loss: 6.2111e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "301/301 [==============================] - 20s 65ms/step - loss: 3.6051e-04 - accuracy: 1.0000 - val_loss: 5.2088e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "301/301 [==============================] - 19s 64ms/step - loss: 3.0522e-04 - accuracy: 1.0000 - val_loss: 4.4900e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "301/301 [==============================] - 20s 65ms/step - loss: 2.7241e-04 - accuracy: 1.0000 - val_loss: 4.1944e-04 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "301/301 [==============================] - 20s 66ms/step - loss: 2.5457e-04 - accuracy: 1.0000 - val_loss: 3.9320e-04 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "loss of 0.0002417376235825941; accuracy of 100.0%\n",
      "predictions on a small set of test data--\n",
      "\n",
      "Two   Five   Ten   Nine   Four   One   Ten   Eight   Six   Two   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "Two   Five   Ten   Nine   Four   One   Ten   Eight   Six   Two   "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "#from keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "train_path = r'C:\\img\\train'\n",
    "test_path = r'C:\\img\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)\n",
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2)) #to downsample, fix image when bg is dark and we want bright part\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())  #used when output is multidim and you want to make it linear to pass into dense\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\")) #64 is its neurons and it feeds outputs from prev layers  to neurons\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(10,activation =\"softmax\"))\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)\n",
    "\n",
    "# For getting next batch of testing imgs...\n",
    "imgs, labels = next(test_batches) \n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0) #evaluation of training, how good it is\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%') #accuracy\n",
    "\n",
    "\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "word_dict = {0:'One',1:'Ten',2:'Two',3:'Three',4:'Four',5:'Five',6:'Six',7:'Seven',8:'Eight',9:'Nine'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)],\" \")\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0635d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
